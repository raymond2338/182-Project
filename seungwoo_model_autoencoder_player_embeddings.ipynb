{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "x_y = pd.read_csv(\"x_y_added_player_stat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_y.drop(columns=[\"home_team_api_id\", \"away_team_api_id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x_y.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "home_team_formation = np.concatenate((np.array(df.columns[1:12]), np.array(df.columns[23:34])), axis=0)\n",
    "home_team_stats = np.array(df.columns[67:76])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "away_team_formation = np.concatenate((np.array(df.columns[12:23]), np.array(df.columns[34:45])), axis=0)\n",
    "away_team_stats = np.array(df.columns[76:85])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_player_stats = np.array(df.columns[87:505])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "away_player_stats = np.array(df.columns[505:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "rearranged_feature_cols = np.concatenate((home_team_stats, home_player_stats, away_team_stats, away_player_stats), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[np.concatenate((rearranged_feature_cols, ['label_home']), axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_rate_unique = set()\n",
    "work_rate_cols = []\n",
    "for i in range(1, 12):\n",
    "    work_rate_cols.append('home_player_'+str(i)+'_attacking_work_rate')\n",
    "    work_rate_cols.append('away_player_'+str(i)+'_attacking_work_rate')\n",
    "    work_rate_cols.append('home_player_'+str(i)+'_defensive_work_rate')    \n",
    "    work_rate_cols.append('away_player_'+str(i)+'_defensive_work_rate')\n",
    "for col in work_rate_cols:\n",
    "    for index in df[col].value_counts().index:\n",
    "        work_rate_unique.add(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [\"high\", \"low\", \"medium\"]:\n",
    "    work_rate_unique.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_map = dict(zip(work_rate_unique, [\"medium\"]*len(work_rate_unique)))\n",
    "for col in work_rate_cols:\n",
    "    df[col].replace(replace_map, inplace=True)\n",
    "    df[col].fillna(\"medium\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i used average throughout players in same position, but better would be average within the team. best is average within the same position in the team would be the best but we do not have info on that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables = ['_preferred_foot', '_attacking_work_rate', '_defensive_work_rate']\n",
    "categorical_cols = []\n",
    "for i in range(1, 12):\n",
    "    for cat in categorical_variables:\n",
    "        categorical_cols.append('home_player_'+str(i)+cat)\n",
    "for i in range(1, 12):\n",
    "    for cat in categorical_variables:\n",
    "        categorical_cols.append('away_player_'+str(i)+cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['home_buildUpPlaySpeed', 'home_buildUpPlayDribbling',\n",
       "       'home_buildUpPlayPassing', 'home_chanceCreationPassing',\n",
       "       'home_chanceCreationCrossing', 'home_chanceCreationShooting',\n",
       "       'home_defencePressure', 'home_defenceAggression',\n",
       "       'home_defenceTeamWidth', 'home_player_1_overall_rating',\n",
       "       ...\n",
       "       'away_player_11_vision', 'away_player_11_penalties',\n",
       "       'away_player_11_marking', 'away_player_11_standing_tackle',\n",
       "       'away_player_11_sliding_tackle', 'away_player_11_gk_diving',\n",
       "       'away_player_11_gk_handling', 'away_player_11_gk_kicking',\n",
       "       'away_player_11_gk_positioning', 'away_player_11_gk_reflexes'],\n",
       "      dtype='object', length=854)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cleaned[\"match_api_id\"] = x_y[\"match_api_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cleaned.to_csv(\"cleaned_data_notEncoded.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_cleaned.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_col = player_attributes.columns[4:].tolist()\n",
    "attributes_col.remove(\"preferred_foot\")\n",
    "attributes_col.remove(\"attacking_work_rate\")\n",
    "attributes_col.remove(\"defensive_work_rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nameColumns(playerNum, homeOrAway):\n",
    "    cols = attributes_col\n",
    "    player_cols = []\n",
    "    for col in cols:\n",
    "        player_cols.append(homeOrAway + \"_player_\" + str(playerNum) + \"_\" + col)\n",
    "    return player_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df_temp[nameColumns(1, \"home\")].values\n",
    "for i in range(2, 12):\n",
    "    temp = np.concatenate((temp, df_temp[nameColumns(i, \"home\")].values, df_temp[nameColumns(i, \"away\")].values), axis=0)\n",
    "autoencoder_data = pd.DataFrame(temp)\n",
    "autoencoder_data.columns = attributes_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungwooson/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype object were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler().fit(autoencoder_data)\n",
    "autoencoder_data = scaler.transform(autoencoder_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(autoencoder_data, autoencoder_data[:,-1], \n",
    "                                                    test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungwooson/anaconda/lib/python3.5/site-packages/keras/activations.py:115: UserWarning: Do not pass a layer instance (such as PReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 358071 samples, validate on 63189 samples\n",
      "Epoch 1/10\n",
      "358071/358071 [==============================] - 13s 36us/step - loss: 0.0284 - val_loss: 0.0153\n",
      "Epoch 2/10\n",
      "358071/358071 [==============================] - 12s 35us/step - loss: 0.0123 - val_loss: 0.0106\n",
      "Epoch 3/10\n",
      "358071/358071 [==============================] - 12s 33us/step - loss: 0.0097 - val_loss: 0.0088\n",
      "Epoch 4/10\n",
      "358071/358071 [==============================] - 12s 34us/step - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 5/10\n",
      "358071/358071 [==============================] - 12s 33us/step - loss: 0.0076 - val_loss: 0.0074\n",
      "Epoch 6/10\n",
      "358071/358071 [==============================] - 12s 34us/step - loss: 0.0074 - val_loss: 0.0073\n",
      "Epoch 7/10\n",
      "358071/358071 [==============================] - 12s 34us/step - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 8/10\n",
      "358071/358071 [==============================] - 13s 37us/step - loss: 0.0071 - val_loss: 0.0071\n",
      "Epoch 9/10\n",
      "358071/358071 [==============================] - 13s 37us/step - loss: 0.0070 - val_loss: 0.0070\n",
      "Epoch 10/10\n",
      "358071/358071 [==============================] - 12s 35us/step - loss: 0.0070 - val_loss: 0.0069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17f59e208>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, PReLU\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "\n",
    "encoding_dim = 3\n",
    "\n",
    "input_img = Input(shape=(autoencoder_data.shape[1],))\n",
    "encoded = Dense(15, activation=PReLU())(input_img)\n",
    "# encoded = Dense(16, activation='relu')(encoded)\n",
    "encoded = Dense(encoding_dim, activation=PReLU())(encoded)\n",
    "\n",
    "decoded = Dense(15, activation=PReLU())(encoded)\n",
    "# decoded = Dense(32, activation='relu')(decoded)\n",
    "decoded = Dense(autoencoder_data.shape[1], activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "encoder = Model(input_img, encoded)\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-2](encoded_input)\n",
    "# decoder_layer = autoencoder.layers[-2](decoder_layer)\n",
    "decoder_layer = autoencoder.layers[-1](decoder_layer)\n",
    "decoder = Model(encoded_input, decoder_layer)\n",
    "\n",
    "adam = optimizers.Adam(lr=5e-5, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "autoencoder.compile(optimizer=adam, loss='mse')\n",
    "\n",
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs=10,\n",
    "                batch_size=64,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_test, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced player stat dimensions from 770 dimensions -> 66 dimensions\n"
     ]
    }
   ],
   "source": [
    "print(\"Reduced player stat dimensions from %d dimensions -> %d dimensions\" % (autoencoder_data.shape[1]*11*2, encoding_dim*11*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maybe take out overall stat, take out gk?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[778.6596 , 430.97665, 422.58862],\n",
       "       [850.8912 , 484.18942, 438.37717],\n",
       "       [920.72797, 465.07742, 498.03577],\n",
       "       ...,\n",
       "       [791.35583, 476.00183, 260.3753 ],\n",
       "       [936.47595, 306.2982 , 310.84268],\n",
       "       [971.364  , 346.57587, 304.6196 ]], dtype=float32)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.predict(df_temp[nameColumns(11, \"home\")].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline without Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_cleaned.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric_cols = np.concatenate((categorical_cols, home_team_formation, away_team_formation), axis=0)\n",
    "numeric_cols = [col for col in df_temp.columns[:-1] if col not in non_numeric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler().fit(df_temp[numeric_cols])\n",
    "df_temp[numeric_cols] = scaler.transform(df_temp[numeric_cols])\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_temp[numeric_cols], df_temp.iloc[:,-1], \n",
    "                                                    test_size=0.15, random_state=0)\n",
    "from keras.utils import np_utils\n",
    "y_train, y_test = [i+1 for i in y_train], [i+1 for i in y_test]\n",
    "y_train_enc, y_test_enc = np_utils.to_categorical(y_train), np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17051 samples, validate on 3009 samples\n",
      "Epoch 1/50\n",
      "17051/17051 [==============================] - 4s 234us/step - loss: 1.1936 - acc: 0.2582 - val_loss: 1.1675 - val_acc: 0.2629\n",
      "Epoch 2/50\n",
      "17051/17051 [==============================] - 2s 112us/step - loss: 1.1685 - acc: 0.2583 - val_loss: 1.1465 - val_acc: 0.2659\n",
      "Epoch 3/50\n",
      "17051/17051 [==============================] - 2s 112us/step - loss: 1.1510 - acc: 0.2595 - val_loss: 1.1312 - val_acc: 0.2702\n",
      "Epoch 4/50\n",
      "17051/17051 [==============================] - 2s 112us/step - loss: 1.1379 - acc: 0.2671 - val_loss: 1.1198 - val_acc: 0.2815\n",
      "Epoch 5/50\n",
      "17051/17051 [==============================] - 2s 112us/step - loss: 1.1278 - acc: 0.2823 - val_loss: 1.1109 - val_acc: 0.2981\n",
      "Epoch 6/50\n",
      "17051/17051 [==============================] - 2s 110us/step - loss: 1.1197 - acc: 0.3054 - val_loss: 1.1038 - val_acc: 0.3177\n",
      "Epoch 7/50\n",
      "17051/17051 [==============================] - 2s 110us/step - loss: 1.1133 - acc: 0.3307 - val_loss: 1.0981 - val_acc: 0.3503\n",
      "Epoch 8/50\n",
      "17051/17051 [==============================] - 2s 110us/step - loss: 1.1081 - acc: 0.3626 - val_loss: 1.0934 - val_acc: 0.3845\n",
      "Epoch 9/50\n",
      "17051/17051 [==============================] - 2s 111us/step - loss: 1.1037 - acc: 0.3899 - val_loss: 1.0896 - val_acc: 0.4138\n",
      "Epoch 10/50\n",
      "17051/17051 [==============================] - 2s 112us/step - loss: 1.1000 - acc: 0.4101 - val_loss: 1.0864 - val_acc: 0.4310\n",
      "Epoch 11/50\n",
      "17051/17051 [==============================] - 2s 109us/step - loss: 1.0969 - acc: 0.4265 - val_loss: 1.0837 - val_acc: 0.4510\n",
      "Epoch 12/50\n",
      "17051/17051 [==============================] - 2s 112us/step - loss: 1.0943 - acc: 0.4382 - val_loss: 1.0814 - val_acc: 0.4573\n",
      "Epoch 13/50\n",
      "17051/17051 [==============================] - 2s 111us/step - loss: 1.0920 - acc: 0.4441 - val_loss: 1.0795 - val_acc: 0.4646\n",
      "Epoch 14/50\n",
      "17051/17051 [==============================] - 2s 115us/step - loss: 1.0900 - acc: 0.4489 - val_loss: 1.0777 - val_acc: 0.4683\n",
      "Epoch 15/50\n",
      "17051/17051 [==============================] - 2s 118us/step - loss: 1.0882 - acc: 0.4523 - val_loss: 1.0762 - val_acc: 0.4689\n",
      "Epoch 16/50\n",
      "17051/17051 [==============================] - 2s 118us/step - loss: 1.0866 - acc: 0.4530 - val_loss: 1.0749 - val_acc: 0.4713\n",
      "Epoch 17/50\n",
      "17051/17051 [==============================] - 2s 117us/step - loss: 1.0851 - acc: 0.4539 - val_loss: 1.0738 - val_acc: 0.4713\n",
      "Epoch 18/50\n",
      "17051/17051 [==============================] - 2s 123us/step - loss: 1.0837 - acc: 0.4549 - val_loss: 1.0727 - val_acc: 0.4709\n",
      "Epoch 19/50\n",
      "17051/17051 [==============================] - 2s 114us/step - loss: 1.0825 - acc: 0.4549 - val_loss: 1.0717 - val_acc: 0.4696\n",
      "Epoch 20/50\n",
      "17051/17051 [==============================] - 2s 114us/step - loss: 1.0814 - acc: 0.4550 - val_loss: 1.0708 - val_acc: 0.4706\n",
      "Epoch 21/50\n",
      "17051/17051 [==============================] - 2s 113us/step - loss: 1.0803 - acc: 0.4550 - val_loss: 1.0700 - val_acc: 0.4709\n",
      "Epoch 22/50\n",
      "17051/17051 [==============================] - 2s 108us/step - loss: 1.0793 - acc: 0.4551 - val_loss: 1.0692 - val_acc: 0.4709\n",
      "Epoch 23/50\n",
      "17051/17051 [==============================] - 2s 114us/step - loss: 1.0784 - acc: 0.4551 - val_loss: 1.0685 - val_acc: 0.4713\n",
      "Epoch 24/50\n",
      "17051/17051 [==============================] - 2s 119us/step - loss: 1.0776 - acc: 0.4553 - val_loss: 1.0679 - val_acc: 0.4713\n",
      "Epoch 25/50\n",
      "17051/17051 [==============================] - 2s 119us/step - loss: 1.0768 - acc: 0.4553 - val_loss: 1.0673 - val_acc: 0.4713\n",
      "Epoch 26/50\n",
      "17051/17051 [==============================] - 2s 115us/step - loss: 1.0761 - acc: 0.4553 - val_loss: 1.0668 - val_acc: 0.4713\n",
      "Epoch 27/50\n",
      "17051/17051 [==============================] - 2s 115us/step - loss: 1.0754 - acc: 0.4553 - val_loss: 1.0663 - val_acc: 0.4709\n",
      "Epoch 28/50\n",
      "17051/17051 [==============================] - 2s 114us/step - loss: 1.0748 - acc: 0.4553 - val_loss: 1.0658 - val_acc: 0.4709\n",
      "Epoch 29/50\n",
      "17051/17051 [==============================] - 2s 112us/step - loss: 1.0743 - acc: 0.4553 - val_loss: 1.0655 - val_acc: 0.4709\n",
      "Epoch 30/50\n",
      "17051/17051 [==============================] - 2s 113us/step - loss: 1.0738 - acc: 0.4553 - val_loss: 1.0651 - val_acc: 0.4709\n",
      "Epoch 31/50\n",
      "17051/17051 [==============================] - 2s 112us/step - loss: 1.0733 - acc: 0.4554 - val_loss: 1.0648 - val_acc: 0.4709\n",
      "Epoch 32/50\n",
      "17051/17051 [==============================] - 2s 113us/step - loss: 1.0729 - acc: 0.4553 - val_loss: 1.0645 - val_acc: 0.4709\n",
      "Epoch 33/50\n",
      "17051/17051 [==============================] - 2s 106us/step - loss: 1.0725 - acc: 0.4553 - val_loss: 1.0642 - val_acc: 0.4709\n",
      "Epoch 34/50\n",
      "17051/17051 [==============================] - 2s 109us/step - loss: 1.0722 - acc: 0.4553 - val_loss: 1.0640 - val_acc: 0.4709\n",
      "Epoch 35/50\n",
      "17051/17051 [==============================] - 2s 111us/step - loss: 1.0719 - acc: 0.4553 - val_loss: 1.0637 - val_acc: 0.4709\n",
      "Epoch 36/50\n",
      "17051/17051 [==============================] - 2s 115us/step - loss: 1.0716 - acc: 0.4553 - val_loss: 1.0635 - val_acc: 0.4709\n",
      "Epoch 37/50\n",
      "17051/17051 [==============================] - 2s 112us/step - loss: 1.0714 - acc: 0.4553 - val_loss: 1.0633 - val_acc: 0.4709\n",
      "Epoch 38/50\n",
      "17051/17051 [==============================] - 2s 115us/step - loss: 1.0711 - acc: 0.4553 - val_loss: 1.0631 - val_acc: 0.4709\n",
      "Epoch 39/50\n",
      "17051/17051 [==============================] - 2s 112us/step - loss: 1.0709 - acc: 0.4553 - val_loss: 1.0629 - val_acc: 0.4709\n",
      "Epoch 40/50\n",
      "17051/17051 [==============================] - 2s 120us/step - loss: 1.0707 - acc: 0.4553 - val_loss: 1.0628 - val_acc: 0.4709\n",
      "Epoch 41/50\n",
      "17051/17051 [==============================] - 2s 112us/step - loss: 1.0705 - acc: 0.4553 - val_loss: 1.0626 - val_acc: 0.4709\n",
      "Epoch 42/50\n",
      "17051/17051 [==============================] - 2s 110us/step - loss: 1.0703 - acc: 0.4553 - val_loss: 1.0625 - val_acc: 0.4709\n",
      "Epoch 43/50\n",
      "17051/17051 [==============================] - 2s 112us/step - loss: 1.0701 - acc: 0.4553 - val_loss: 1.0624 - val_acc: 0.4709\n",
      "Epoch 44/50\n",
      "17051/17051 [==============================] - 2s 103us/step - loss: 1.0700 - acc: 0.4553 - val_loss: 1.0623 - val_acc: 0.4709\n",
      "Epoch 45/50\n",
      "17051/17051 [==============================] - 2s 114us/step - loss: 1.0698 - acc: 0.4553 - val_loss: 1.0621 - val_acc: 0.4709\n",
      "Epoch 46/50\n",
      "17051/17051 [==============================] - 2s 123us/step - loss: 1.0697 - acc: 0.4553 - val_loss: 1.0620 - val_acc: 0.4709\n",
      "Epoch 47/50\n",
      "17051/17051 [==============================] - 2s 119us/step - loss: 1.0696 - acc: 0.4553 - val_loss: 1.0619 - val_acc: 0.4709\n",
      "Epoch 48/50\n",
      "17051/17051 [==============================] - 2s 113us/step - loss: 1.0695 - acc: 0.4553 - val_loss: 1.0618 - val_acc: 0.4709\n",
      "Epoch 49/50\n",
      "17051/17051 [==============================] - 2s 115us/step - loss: 1.0694 - acc: 0.4553 - val_loss: 1.0618 - val_acc: 0.4709\n",
      "Epoch 50/50\n",
      "17051/17051 [==============================] - 2s 111us/step - loss: 1.0693 - acc: 0.4553 - val_loss: 1.0617 - val_acc: 0.4709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ec7f3c50>"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "opt = SGD(lr=1e-5)\n",
    "# adam = keras.optimizers.Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "from keras.initializers import glorot_normal\n",
    "\n",
    "def MLP(input_dim):\n",
    "    xavier_init = glorot_normal(seed=35)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=32, activation='relu', kernel_initializer=xavier_init, input_dim=input_dim))\n",
    "    model.add(Dense(units=16, activation='relu', kernel_initializer=xavier_init))\n",
    "    model.add(Dense(units=3, activation='softmax', kernel_initializer=xavier_init))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = MLP(X_train.shape[1])\n",
    "model.fit(x=X_train, y=y_train_enc, validation_data=(X_test, y_test_enc), batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3009/3009 [==============================] - 0s 71us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0616693132816655, 0.4709205716184779]"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline with Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_category = df_cleaned.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables = ['_preferred_foot', '_attacking_work_rate', '_defensive_work_rate']\n",
    "categorical_cols = []\n",
    "for i in range(1, 12):\n",
    "    for cat in categorical_variables:\n",
    "        categorical_cols.append('home_player_'+str(i)+cat)\n",
    "for i in range(1, 12):\n",
    "    for cat in categorical_variables:\n",
    "        categorical_cols.append('away_player_'+str(i)+cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric_cols = np.concatenate((categorical_cols, home_team_formation, away_team_formation), axis=0)\n",
    "numeric_cols = [col for col in df_with_category.columns[:-1] if col not in non_numeric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler().fit(df_with_category[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_category[numeric_cols] = scaler.transform(df_with_category[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_with_category.iloc[:,:-1], df_with_category.iloc[:,-1], \n",
    "                                                    test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dummy = pd.get_dummies(pd.DataFrame(X_train, columns=df_with_category.iloc[:,:-1].columns), columns=categorical_cols)\n",
    "X_test_dummy = pd.get_dummies(pd.DataFrame(X_test, columns=df_with_category.iloc[:,:-1].columns), columns=categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_non_dummy = np.array(X_train_dummy.columns[:394])\n",
    "away_non_dummy = np.array(X_train_dummy.columns[394:788])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dummy_col = np.array(X_train_dummy.columns[788:873])\n",
    "away_dummy_col = np.array(X_train_dummy.columns[873:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "rearranged_feature_cols = np.concatenate((home_non_dummy, home_dummy_col, away_non_dummy, away_dummy_col), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dummy = X_train_dummy[rearranged_feature_cols]\n",
    "missing_cols = set(X_train_dummy.columns)-set(X_test_dummy.columns)\n",
    "for c in missing_cols:\n",
    "    X_test_dummy[c] = 0\n",
    "X_test_dummy = X_test_dummy[X_train_dummy.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "gk_cols = []\n",
    "for i in range(2, 12):\n",
    "    gk_cols.append(\"home_player_\"+str(i)+\"_gk_diving\")\n",
    "    gk_cols.append(\"home_player_\"+str(i)+\"_gk_handling\")\n",
    "    gk_cols.append(\"home_player_\"+str(i)+\"_gk_kicking\")\n",
    "    gk_cols.append(\"home_player_\"+str(i)+\"_gk_positioning\")\n",
    "    gk_cols.append(\"home_player_\"+str(i)+\"_gk_reflexes\")\n",
    "    gk_cols.append(\"away_player_\"+str(i)+\"_gk_diving\")\n",
    "    gk_cols.append(\"away_player_\"+str(i)+\"_gk_handling\")\n",
    "    gk_cols.append(\"away_player_\"+str(i)+\"_gk_kicking\")\n",
    "    gk_cols.append(\"away_player_\"+str(i)+\"_gk_positioning\")\n",
    "    gk_cols.append(\"away_player_\"+str(i)+\"_gk_reflexes\")\n",
    "X_train_final = X_train_dummy.drop(columns=gk_cols)\n",
    "X_test_final = X_test_dummy.drop(columns=gk_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "y_train, y_test = [i+1 for i in y_train], [i+1 for i in y_test]\n",
    "y_train_encoded = np_utils.to_categorical(y_train)\n",
    "y_test_encoded = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungwooson/anaconda/lib/python3.5/site-packages/keras/activations.py:115: UserWarning: Do not pass a layer instance (such as ELU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17051 samples, validate on 3009 samples\n",
      "Epoch 1/50\n",
      "17051/17051 [==============================] - 4s 251us/step - loss: 1.0822 - acc: 0.4423 - val_loss: 1.0657 - val_acc: 0.4716\n",
      "Epoch 2/50\n",
      "17051/17051 [==============================] - 2s 123us/step - loss: 1.0735 - acc: 0.4501 - val_loss: 1.0641 - val_acc: 0.4713\n",
      "Epoch 3/50\n",
      "17051/17051 [==============================] - 2s 124us/step - loss: 1.0712 - acc: 0.4537 - val_loss: 1.0733 - val_acc: 0.4573\n",
      "Epoch 4/50\n",
      "17051/17051 [==============================] - 2s 124us/step - loss: 1.0690 - acc: 0.4545 - val_loss: 1.0623 - val_acc: 0.4713\n",
      "Epoch 5/50\n",
      "17051/17051 [==============================] - 2s 126us/step - loss: 1.0671 - acc: 0.4546 - val_loss: 1.0669 - val_acc: 0.4703\n",
      "Epoch 6/50\n",
      "17051/17051 [==============================] - 2s 123us/step - loss: 1.0670 - acc: 0.4544 - val_loss: 1.0695 - val_acc: 0.4676\n",
      "Epoch 7/50\n",
      "17051/17051 [==============================] - 2s 128us/step - loss: 1.0654 - acc: 0.4562 - val_loss: 1.0649 - val_acc: 0.4709\n",
      "Epoch 8/50\n",
      "17051/17051 [==============================] - 2s 124us/step - loss: 1.0645 - acc: 0.4555 - val_loss: 1.0647 - val_acc: 0.4709\n",
      "Epoch 9/50\n",
      "17051/17051 [==============================] - 2s 126us/step - loss: 1.0647 - acc: 0.4549 - val_loss: 1.0630 - val_acc: 0.4709\n",
      "Epoch 10/50\n",
      "17051/17051 [==============================] - 2s 124us/step - loss: 1.0637 - acc: 0.4559 - val_loss: 1.0628 - val_acc: 0.4709\n",
      "Epoch 11/50\n",
      "17051/17051 [==============================] - 2s 127us/step - loss: 1.0633 - acc: 0.4553 - val_loss: 1.0658 - val_acc: 0.4693\n",
      "Epoch 12/50\n",
      "17051/17051 [==============================] - 2s 125us/step - loss: 1.0616 - acc: 0.4556 - val_loss: 1.0656 - val_acc: 0.4703\n",
      "Epoch 13/50\n",
      "17051/17051 [==============================] - 2s 128us/step - loss: 1.0617 - acc: 0.4560 - val_loss: 1.0654 - val_acc: 0.4703\n",
      "Epoch 14/50\n",
      "17051/17051 [==============================] - 2s 119us/step - loss: 1.0612 - acc: 0.4556 - val_loss: 1.0644 - val_acc: 0.4709\n",
      "Epoch 15/50\n",
      "17051/17051 [==============================] - 2s 128us/step - loss: 1.0602 - acc: 0.4552 - val_loss: 1.0640 - val_acc: 0.4709\n",
      "Epoch 16/50\n",
      "17051/17051 [==============================] - 2s 133us/step - loss: 1.0604 - acc: 0.4565 - val_loss: 1.0664 - val_acc: 0.4706\n",
      "Epoch 17/50\n",
      "17051/17051 [==============================] - 2s 132us/step - loss: 1.0603 - acc: 0.4548 - val_loss: 1.0644 - val_acc: 0.4703\n",
      "Epoch 18/50\n",
      "17051/17051 [==============================] - 2s 132us/step - loss: 1.0594 - acc: 0.4573 - val_loss: 1.0664 - val_acc: 0.4699\n",
      "Epoch 19/50\n",
      "17051/17051 [==============================] - 2s 138us/step - loss: 1.0591 - acc: 0.4565 - val_loss: 1.0657 - val_acc: 0.4703\n",
      "Epoch 20/50\n",
      "17051/17051 [==============================] - 2s 130us/step - loss: 1.0583 - acc: 0.4565 - val_loss: 1.0682 - val_acc: 0.4703\n",
      "Epoch 21/50\n",
      "17051/17051 [==============================] - 2s 136us/step - loss: 1.0579 - acc: 0.4559 - val_loss: 1.0694 - val_acc: 0.4666\n",
      "Epoch 22/50\n",
      "17051/17051 [==============================] - 2s 126us/step - loss: 1.0579 - acc: 0.4553 - val_loss: 1.0698 - val_acc: 0.4590\n",
      "Epoch 23/50\n",
      "17051/17051 [==============================] - 2s 124us/step - loss: 1.0570 - acc: 0.4570 - val_loss: 1.0715 - val_acc: 0.4629\n",
      "Epoch 24/50\n",
      "17051/17051 [==============================] - 2s 123us/step - loss: 1.0561 - acc: 0.4569 - val_loss: 1.0700 - val_acc: 0.4613\n",
      "Epoch 25/50\n",
      "17051/17051 [==============================] - 2s 124us/step - loss: 1.0567 - acc: 0.4560 - val_loss: 1.0689 - val_acc: 0.4663\n",
      "Epoch 26/50\n",
      "17051/17051 [==============================] - 2s 123us/step - loss: 1.0564 - acc: 0.4561 - val_loss: 1.0663 - val_acc: 0.4706\n",
      "Epoch 27/50\n",
      "17051/17051 [==============================] - 2s 127us/step - loss: 1.0545 - acc: 0.4558 - val_loss: 1.0735 - val_acc: 0.4706\n",
      "Epoch 28/50\n",
      "17051/17051 [==============================] - 2s 124us/step - loss: 1.0543 - acc: 0.4586 - val_loss: 1.0732 - val_acc: 0.4516\n",
      "Epoch 29/50\n",
      "17051/17051 [==============================] - 2s 124us/step - loss: 1.0536 - acc: 0.4599 - val_loss: 1.0687 - val_acc: 0.4706\n",
      "Epoch 30/50\n",
      "17051/17051 [==============================] - 2s 124us/step - loss: 1.0529 - acc: 0.4584 - val_loss: 1.0716 - val_acc: 0.4560\n",
      "Epoch 31/50\n",
      "17051/17051 [==============================] - 2s 126us/step - loss: 1.0527 - acc: 0.4569 - val_loss: 1.0796 - val_acc: 0.4393\n",
      "Epoch 32/50\n",
      "17051/17051 [==============================] - 2s 124us/step - loss: 1.0527 - acc: 0.4597 - val_loss: 1.0724 - val_acc: 0.4576\n",
      "Epoch 33/50\n",
      "17051/17051 [==============================] - 2s 124us/step - loss: 1.0523 - acc: 0.4592 - val_loss: 1.0722 - val_acc: 0.4613\n",
      "Epoch 34/50\n",
      "17051/17051 [==============================] - 2s 125us/step - loss: 1.0506 - acc: 0.4604 - val_loss: 1.0690 - val_acc: 0.4683\n",
      "Epoch 35/50\n",
      "17051/17051 [==============================] - 2s 126us/step - loss: 1.0499 - acc: 0.4597 - val_loss: 1.0775 - val_acc: 0.4467\n",
      "Epoch 36/50\n",
      "17051/17051 [==============================] - 2s 125us/step - loss: 1.0495 - acc: 0.4627 - val_loss: 1.0714 - val_acc: 0.4703\n",
      "Epoch 37/50\n",
      "17051/17051 [==============================] - 2s 124us/step - loss: 1.0497 - acc: 0.4635 - val_loss: 1.0820 - val_acc: 0.4207\n",
      "Epoch 38/50\n",
      "17051/17051 [==============================] - 2s 124us/step - loss: 1.0485 - acc: 0.4632 - val_loss: 1.0747 - val_acc: 0.4490\n",
      "Epoch 39/50\n",
      "17051/17051 [==============================] - 2s 124us/step - loss: 1.0463 - acc: 0.4643 - val_loss: 1.0787 - val_acc: 0.4500\n",
      "Epoch 40/50\n",
      "17051/17051 [==============================] - 2s 124us/step - loss: 1.0475 - acc: 0.4630 - val_loss: 1.0866 - val_acc: 0.4214\n",
      "Epoch 41/50\n",
      "17051/17051 [==============================] - 2s 126us/step - loss: 1.0468 - acc: 0.4611 - val_loss: 1.0744 - val_acc: 0.4543\n",
      "Epoch 42/50\n",
      "17051/17051 [==============================] - 2s 125us/step - loss: 1.0460 - acc: 0.4637 - val_loss: 1.0774 - val_acc: 0.4490\n",
      "Epoch 43/50\n",
      "17051/17051 [==============================] - 2s 120us/step - loss: 1.0453 - acc: 0.4653 - val_loss: 1.0788 - val_acc: 0.4453\n",
      "Epoch 44/50\n",
      "17051/17051 [==============================] - 2s 124us/step - loss: 1.0442 - acc: 0.4665 - val_loss: 1.0790 - val_acc: 0.4636\n",
      "Epoch 45/50\n",
      "17051/17051 [==============================] - 2s 124us/step - loss: 1.0439 - acc: 0.4668 - val_loss: 1.0812 - val_acc: 0.4294\n",
      "Epoch 46/50\n",
      "17051/17051 [==============================] - 2s 124us/step - loss: 1.0433 - acc: 0.4655 - val_loss: 1.0746 - val_acc: 0.4669\n",
      "Epoch 47/50\n",
      "17051/17051 [==============================] - 2s 124us/step - loss: 1.0424 - acc: 0.4657 - val_loss: 1.0748 - val_acc: 0.4516\n",
      "Epoch 48/50\n",
      "17051/17051 [==============================] - 2s 124us/step - loss: 1.0421 - acc: 0.4650 - val_loss: 1.0771 - val_acc: 0.4443\n",
      "Epoch 49/50\n",
      "17051/17051 [==============================] - 2s 128us/step - loss: 1.0397 - acc: 0.4690 - val_loss: 1.0812 - val_acc: 0.4643\n",
      "Epoch 50/50\n",
      "17051/17051 [==============================] - 2s 128us/step - loss: 1.0390 - acc: 0.4715 - val_loss: 1.0891 - val_acc: 0.4693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1893597f0>"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "adam = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "def MLP(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=32, activation=ELU(), input_dim=input_dim))\n",
    "#     model.add(Dropout(0.8))\n",
    "    model.add(Dense(units=16, activation=ELU()))\n",
    "    model.add(Dense(units=3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = MLP(X_train_final.shape[1])\n",
    "model.fit(x=X_train_final, y=y_train_encoded, validation_data=(X_test_final, y_test_encoded), batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3009/3009 [==============================] - 0s 77us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0891221275991996, 0.46925888999667664]"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_final, y_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Features Generated by Autoencoders, without Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_cleaned.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric_cols = np.concatenate((categorical_cols, home_team_formation, away_team_formation), axis=0)\n",
    "numeric_cols = [col for col in df_temp.columns[:-1] if col not in non_numeric_cols]\n",
    "df_X = df_temp[numeric_cols]\n",
    "y_label = df_temp.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_emb = df_X[home_team_stats]\n",
    "for i in range(1, 12):\n",
    "    df_X_emb = pd.concat([df_X_emb, pd.DataFrame(encoder.predict(df_X[nameColumns(i, \"home\")].values))], axis=1)\n",
    "df_X_emb = pd.concat([df_X_emb, df_X[away_team_stats]], axis=1)\n",
    "for i in range(1, 12):\n",
    "    df_X_emb = pd.concat([df_X_emb, pd.DataFrame(encoder.predict(df_X[nameColumns(i, \"away\")].values))], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seungwooson/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype float32, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler().fit(df_X_emb)\n",
    "df_X_emb = scaler.transform(df_X_emb)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X_emb, y_label, \n",
    "                                                    test_size=0.15, random_state=0)\n",
    "from keras.utils import np_utils\n",
    "y_train, y_test = [i+1 for i in y_train], [i+1 for i in y_test]\n",
    "y_train_enc, y_test_enc = np_utils.to_categorical(y_train), np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17051 samples, validate on 3009 samples\n",
      "Epoch 1/50\n",
      "17051/17051 [==============================] - 6s 329us/step - loss: 1.1376 - acc: 0.2755 - val_loss: 1.1059 - val_acc: 0.3167\n",
      "Epoch 2/50\n",
      "17051/17051 [==============================] - 3s 202us/step - loss: 1.0917 - acc: 0.3864 - val_loss: 1.0805 - val_acc: 0.4506\n",
      "Epoch 3/50\n",
      "17051/17051 [==============================] - 3s 200us/step - loss: 1.0777 - acc: 0.4461 - val_loss: 1.0716 - val_acc: 0.4686\n",
      "Epoch 4/50\n",
      "17051/17051 [==============================] - 3s 200us/step - loss: 1.0730 - acc: 0.4537 - val_loss: 1.0682 - val_acc: 0.4716\n",
      "Epoch 5/50\n",
      "17051/17051 [==============================] - 3s 197us/step - loss: 1.0712 - acc: 0.4545 - val_loss: 1.0666 - val_acc: 0.4709\n",
      "Epoch 6/50\n",
      "17051/17051 [==============================] - 3s 195us/step - loss: 1.0705 - acc: 0.4552 - val_loss: 1.0657 - val_acc: 0.4709\n",
      "Epoch 7/50\n",
      "17051/17051 [==============================] - 3s 198us/step - loss: 1.0701 - acc: 0.4550 - val_loss: 1.0651 - val_acc: 0.4709\n",
      "Epoch 8/50\n",
      "17051/17051 [==============================] - 4s 214us/step - loss: 1.0698 - acc: 0.4550 - val_loss: 1.0647 - val_acc: 0.4709\n",
      "Epoch 9/50\n",
      "17051/17051 [==============================] - 4s 212us/step - loss: 1.0696 - acc: 0.4552 - val_loss: 1.0644 - val_acc: 0.4709\n",
      "Epoch 10/50\n",
      "17051/17051 [==============================] - 3s 201us/step - loss: 1.0694 - acc: 0.4552 - val_loss: 1.0641 - val_acc: 0.4709\n",
      "Epoch 11/50\n",
      "17051/17051 [==============================] - 4s 216us/step - loss: 1.0693 - acc: 0.4553 - val_loss: 1.0638 - val_acc: 0.4706\n",
      "Epoch 12/50\n",
      "17051/17051 [==============================] - 4s 234us/step - loss: 1.0691 - acc: 0.4553 - val_loss: 1.0636 - val_acc: 0.4706\n",
      "Epoch 13/50\n",
      "17051/17051 [==============================] - 4s 215us/step - loss: 1.0690 - acc: 0.4553 - val_loss: 1.0634 - val_acc: 0.4706\n",
      "Epoch 14/50\n",
      "17051/17051 [==============================] - 4s 210us/step - loss: 1.0689 - acc: 0.4553 - val_loss: 1.0633 - val_acc: 0.4709\n",
      "Epoch 15/50\n",
      "17051/17051 [==============================] - 4s 209us/step - loss: 1.0689 - acc: 0.4553 - val_loss: 1.0632 - val_acc: 0.4709\n",
      "Epoch 16/50\n",
      "17051/17051 [==============================] - 4s 206us/step - loss: 1.0688 - acc: 0.4553 - val_loss: 1.0630 - val_acc: 0.4709\n",
      "Epoch 17/50\n",
      "17051/17051 [==============================] - 3s 200us/step - loss: 1.0687 - acc: 0.4553 - val_loss: 1.0629 - val_acc: 0.4709\n",
      "Epoch 18/50\n",
      "17051/17051 [==============================] - 4s 213us/step - loss: 1.0686 - acc: 0.4553 - val_loss: 1.0628 - val_acc: 0.4709\n",
      "Epoch 19/50\n",
      "17051/17051 [==============================] - 3s 203us/step - loss: 1.0685 - acc: 0.4553 - val_loss: 1.0627 - val_acc: 0.4709\n",
      "Epoch 20/50\n",
      "17051/17051 [==============================] - 3s 202us/step - loss: 1.0684 - acc: 0.4553 - val_loss: 1.0626 - val_acc: 0.4709\n",
      "Epoch 21/50\n",
      "17051/17051 [==============================] - 4s 209us/step - loss: 1.0683 - acc: 0.4553 - val_loss: 1.0625 - val_acc: 0.4709\n",
      "Epoch 22/50\n",
      "17051/17051 [==============================] - 3s 205us/step - loss: 1.0682 - acc: 0.4553 - val_loss: 1.0624 - val_acc: 0.4709\n",
      "Epoch 23/50\n",
      "17051/17051 [==============================] - 3s 202us/step - loss: 1.0681 - acc: 0.4553 - val_loss: 1.0624 - val_acc: 0.4709\n",
      "Epoch 24/50\n",
      "17051/17051 [==============================] - 3s 204us/step - loss: 1.0681 - acc: 0.4553 - val_loss: 1.0623 - val_acc: 0.4709\n",
      "Epoch 25/50\n",
      "17051/17051 [==============================] - 3s 203us/step - loss: 1.0680 - acc: 0.4553 - val_loss: 1.0623 - val_acc: 0.4709\n",
      "Epoch 26/50\n",
      "17051/17051 [==============================] - 4s 222us/step - loss: 1.0679 - acc: 0.4553 - val_loss: 1.0622 - val_acc: 0.4709\n",
      "Epoch 27/50\n",
      "17051/17051 [==============================] - 4s 207us/step - loss: 1.0679 - acc: 0.4553 - val_loss: 1.0622 - val_acc: 0.4709\n",
      "Epoch 28/50\n",
      "17051/17051 [==============================] - 4s 207us/step - loss: 1.0678 - acc: 0.4552 - val_loss: 1.0621 - val_acc: 0.4709\n",
      "Epoch 29/50\n",
      "17051/17051 [==============================] - 3s 199us/step - loss: 1.0677 - acc: 0.4552 - val_loss: 1.0621 - val_acc: 0.4709\n",
      "Epoch 30/50\n",
      "17051/17051 [==============================] - 4s 217us/step - loss: 1.0677 - acc: 0.4553 - val_loss: 1.0620 - val_acc: 0.4709\n",
      "Epoch 31/50\n",
      "17051/17051 [==============================] - 4s 223us/step - loss: 1.0677 - acc: 0.4553 - val_loss: 1.0620 - val_acc: 0.4709\n",
      "Epoch 32/50\n",
      "17051/17051 [==============================] - 4s 230us/step - loss: 1.0676 - acc: 0.4553 - val_loss: 1.0620 - val_acc: 0.4709\n",
      "Epoch 33/50\n",
      "17051/17051 [==============================] - 3s 197us/step - loss: 1.0676 - acc: 0.4553 - val_loss: 1.0619 - val_acc: 0.4709\n",
      "Epoch 34/50\n",
      "17051/17051 [==============================] - 4s 209us/step - loss: 1.0676 - acc: 0.4553 - val_loss: 1.0619 - val_acc: 0.4709\n",
      "Epoch 35/50\n",
      "17051/17051 [==============================] - 4s 214us/step - loss: 1.0675 - acc: 0.4553 - val_loss: 1.0619 - val_acc: 0.4709\n",
      "Epoch 36/50\n",
      "17051/17051 [==============================] - 4s 218us/step - loss: 1.0675 - acc: 0.4553 - val_loss: 1.0619 - val_acc: 0.4709\n",
      "Epoch 37/50\n",
      "17051/17051 [==============================] - 3s 205us/step - loss: 1.0675 - acc: 0.4553 - val_loss: 1.0619 - val_acc: 0.4709\n",
      "Epoch 38/50\n",
      "17051/17051 [==============================] - 4s 221us/step - loss: 1.0674 - acc: 0.4553 - val_loss: 1.0618 - val_acc: 0.4709\n",
      "Epoch 39/50\n",
      "17051/17051 [==============================] - 4s 213us/step - loss: 1.0674 - acc: 0.4553 - val_loss: 1.0618 - val_acc: 0.4709\n",
      "Epoch 40/50\n",
      "17051/17051 [==============================] - 3s 203us/step - loss: 1.0674 - acc: 0.4553 - val_loss: 1.0618 - val_acc: 0.4709\n",
      "Epoch 41/50\n",
      "17051/17051 [==============================] - 4s 209us/step - loss: 1.0674 - acc: 0.4553 - val_loss: 1.0618 - val_acc: 0.4709\n",
      "Epoch 42/50\n",
      "17051/17051 [==============================] - 3s 201us/step - loss: 1.0673 - acc: 0.4553 - val_loss: 1.0618 - val_acc: 0.4709\n",
      "Epoch 43/50\n",
      "17051/17051 [==============================] - 4s 207us/step - loss: 1.0673 - acc: 0.4553 - val_loss: 1.0618 - val_acc: 0.4709\n",
      "Epoch 44/50\n",
      "17051/17051 [==============================] - 3s 200us/step - loss: 1.0673 - acc: 0.4553 - val_loss: 1.0618 - val_acc: 0.4709\n",
      "Epoch 45/50\n",
      "17051/17051 [==============================] - 4s 206us/step - loss: 1.0673 - acc: 0.4553 - val_loss: 1.0617 - val_acc: 0.4709\n",
      "Epoch 46/50\n",
      "17051/17051 [==============================] - 4s 207us/step - loss: 1.0673 - acc: 0.4553 - val_loss: 1.0617 - val_acc: 0.4709\n",
      "Epoch 47/50\n",
      "17051/17051 [==============================] - 4s 209us/step - loss: 1.0672 - acc: 0.4553 - val_loss: 1.0617 - val_acc: 0.4709\n",
      "Epoch 48/50\n",
      "17051/17051 [==============================] - 3s 205us/step - loss: 1.0672 - acc: 0.4553 - val_loss: 1.0617 - val_acc: 0.4709\n",
      "Epoch 49/50\n",
      "17051/17051 [==============================] - 4s 221us/step - loss: 1.0672 - acc: 0.4553 - val_loss: 1.0617 - val_acc: 0.4709\n",
      "Epoch 50/50\n",
      "17051/17051 [==============================] - 4s 217us/step - loss: 1.0672 - acc: 0.4553 - val_loss: 1.0617 - val_acc: 0.4709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22b3388d0>"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "opt = SGD(lr=1e-4)\n",
    "# opt = keras.optimizers.Adam(lr=1e-5, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "from keras.initializers import glorot_normal\n",
    "\n",
    "def MLP(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=32, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dense(units=16, activation='relu'))\n",
    "    model.add(Dense(units=3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = MLP(X_train.shape[1])\n",
    "model.fit(x=X_train, y=y_train_enc, validation_data=(X_test, y_test_enc), batch_size=12, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3009/3009 [==============================] - 0s 76us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0616863330918398, 0.4709205716184779]"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test_enc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
